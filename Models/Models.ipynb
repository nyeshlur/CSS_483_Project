{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import scipy.io\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from interpret import show\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dt(data, label, seed=None):\n",
    "    random.seed(seed)\n",
    "    ones = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 1:\n",
    "            ones.append(i)\n",
    "    zeros = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 0:\n",
    "            zeros.append(i)\n",
    "    zeros = random.sample(zeros, len(ones))\n",
    "    indices = zeros + ones\n",
    "    X = data[indices]\n",
    "    y = label[indices]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_reversed(data, label, seed=None):\n",
    "    random.seed(seed)\n",
    "    zeros = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 0:\n",
    "            zeros.append(i)\n",
    "    ones = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 1:\n",
    "            ones.append(i)\n",
    "    ones = random.sample(ones, len(zeros))\n",
    "    indices = zeros + ones\n",
    "    X = data[indices]\n",
    "    y = label[indices]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_with_kfold(best_clf, x, y, org_dt, org_lb):\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='accuracy')\n",
    "    print(\"balanced accuracy\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='accuracy')\n",
    "    print(\"unbalanced accuracy\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='precision')\n",
    "    print(\"balanced precision\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='precision')\n",
    "    print(\"unbalanced precision\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='recall')\n",
    "    print(\"balanced recall\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='recall')\n",
    "    print(\"unbalanced recall\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='f1')\n",
    "    print(\"balanced f1\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='f1')\n",
    "    print(\"unbalanced f1\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='roc_auc')\n",
    "    print(\"balanced auc\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='roc_auc')\n",
    "    print(\"unbalanced auc\", np.mean(cros_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data.mat')\n",
    "org_dat = mat['OriginalData']\n",
    "stand_dat = mat['Scaled_Standardization']\n",
    "minmax_dat = mat['Scaled_Min_Max']\n",
    "label = mat['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'kernel': ['linear', 'poly', 'rbf'], 'random_state': [i], 'C': [1, 2, 3, 4, 5]}\n",
    "\n",
    "    clf = GridSearchCV(SVC(probability=True), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.5991735897279613\n",
      "SVC(C=5, probability=True, random_state=2)\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.6886952157912345\n",
      "unbalanced accuracy 0.7622667615433271\n",
      "balanced precision 0.7059181851388352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unbalanced precision 0.6553828931606681\n",
      "balanced recall 0.5443755831000933\n",
      "unbalanced recall 0.16064907370385179\n",
      "balanced f1 0.5991735897279613\n",
      "unbalanced f1 0.18514244465670496\n",
      "balanced auc 0.7536066993967441\n",
      "unbalanced auc 0.6301918881335544\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of SVM Results Using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/interpret/visual/udash.py:5: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/interpret/visual/udash.py:6: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/interpret/visual/udash.py:7: UserWarning: \n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n",
      "  import dash_table as dt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140268952080240/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140268952080240/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('svc', svc)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "lime_local = lime.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140269023870640/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140269023870640/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('svc', svc)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "lime_local = lime.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'activation': ['relu'], 'solver': ['sgd'],\n",
    "                  'learning_rate': ['constant'],\n",
    "                  'hidden_layer_sizes': (90,),\n",
    "                  'max_iter': [200, 500, 1000], 'random_state': [i]}\n",
    "\n",
    "    clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.3374760420630415\n",
      "MLPClassifier(hidden_layer_sizes=90, random_state=4, solver='sgd')\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.5895399799263967\n",
      "unbalanced accuracy 0.7567743373009027\n",
      "balanced precision 0.6051753262280142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unbalanced precision 0.12192982456140351\n",
      "balanced recall 0.26246834599493535\n",
      "unbalanced recall 0.021311475409836068\n",
      "balanced f1 0.3374760420630415\n",
      "unbalanced f1 0.0228124569381287\n",
      "balanced auc 0.7413953544265354\n",
      "unbalanced auc 0.7929447367599616\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of CNN Results Using Kernel SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "Using 1953 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959466d721bc461d98e8690691df18ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140269023965728/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140269023965728/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "cnn = MLPClassifier(random_state = seed, max_iter=200)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('cnn', cnn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "shap = ShapKernel(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "shap_local = shap.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Using 4223 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9309548d7f914ba6adf1456354e9b0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140269118508912/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140269118508912/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "cnn = MLPClassifier(random_state = seed, max_iter=200)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('cnn', cnn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "shap = ShapKernel(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "shap_local = shap.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None\n",
    "initial_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'criterion': ['gini', 'entropy'],\n",
    "                  'min_samples_leaf': np.arange(1, 10),\n",
    "                  'min_samples_split': np.arange(2, 10), 'random_state': [i], }\n",
    "\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.6255290077927442\n",
      "DecisionTreeClassifier(min_samples_leaf=9, random_state=4)\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.6502392104382737\n",
      "unbalanced accuracy 0.7198457535506871\n",
      "balanced precision 0.6476550161473279\n",
      "unbalanced precision 0.4931306683568743\n",
      "balanced recall 0.6140677062508331\n",
      "unbalanced recall 0.3646208183393309\n",
      "balanced f1 0.6255290077927442\n",
      "unbalanced f1 0.3536949511516238\n",
      "balanced auc 0.6868991201333674\n",
      "unbalanced auc 0.6460849106808653\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Decision Tree Using Glassbox Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140268601085376/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140268601085376/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "dt = ClassificationTree(random_state=seed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_global = dt.explain_global()\n",
    "\n",
    "show(dt_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140268056667664/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140268056667664/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "dt = ClassificationTree(random_state=seed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_global = dt.explain_global()\n",
    "\n",
    "show(dt_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "                  'random_state': [i], 'max_iter': [100, 300, 500, 1000]}\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='recall')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.3575303212048514\n",
      "LogisticRegression(random_state=1, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.6284459685513549\n",
      "unbalanced accuracy 0.7514713069978725\n",
      "balanced precision 0.666022314096318\n",
      "unbalanced precision 0.3779363060048535\n",
      "balanced recall 0.3575303212048514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unbalanced recall 0.10901639344262293\n",
      "balanced f1 0.4501521820246272\n",
      "unbalanced f1 0.13581061277717327\n",
      "balanced auc 0.7470065525702287\n",
      "unbalanced auc 0.7858452681689594\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Logistic Regression Using Glassbox Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140268053904256/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140268053904256/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import LogisticRegression\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "lr = LogisticRegression(random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140268059388176/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140268059388176/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import LogisticRegression\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "lr = LogisticRegression(random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'n_neighbors': np.arange(1, 11), 'p': [1, 2]}\n",
    "\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='recall')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.641923230707717\n",
      "KNeighborsClassifier(n_neighbors=9)\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.6637420541987287\n",
      "unbalanced accuracy 0.7467371772756024\n",
      "balanced precision 0.6483665445945961\n",
      "unbalanced precision 0.6039004449628574\n",
      "balanced recall 0.641923230707717\n",
      "unbalanced recall 0.30399840063974415\n",
      "balanced f1 0.6394443969273291\n",
      "unbalanced f1 0.3197886957772048\n",
      "balanced auc 0.7149910527592243\n",
      "unbalanced auc 0.6906640722859024\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting KNN Using Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140268600972960/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140268600972960/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('knn', knn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "pdp = PartialDependence(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "pdp_global = pdp.explain_global()\n",
    "\n",
    "show(pdp_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140269090646096/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140269090646096/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('knn', knn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "pdp = PartialDependence(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "pdp_global = pdp.explain_global()\n",
    "\n",
    "show(pdp_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140268059597792/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140268059597792/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "ebm = ExplainableBoostingClassifier(random_state=seed)\n",
    "ebm.fit(X_train, y_train)\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/140268063644832/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/140268063644832/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "ebm = ExplainableBoostingClassifier(random_state=seed)\n",
    "ebm.fit(X_train, y_train)\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
