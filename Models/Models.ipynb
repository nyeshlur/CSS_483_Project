{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import scipy.io\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from interpret import show\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dt(data, label, seed=None):\n",
    "    random.seed(seed)\n",
    "    ones = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 1:\n",
    "            ones.append(i)\n",
    "    zeros = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 0:\n",
    "            zeros.append(i)\n",
    "    zeros = random.sample(zeros, len(ones))\n",
    "    indices = zeros + ones\n",
    "    X = data[indices]\n",
    "    y = label[indices]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_reversed(data, label, seed=None):\n",
    "    random.seed(seed)\n",
    "    zeros = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 0:\n",
    "            zeros.append(i)\n",
    "    ones = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 1:\n",
    "            ones.append(i)\n",
    "    ones = random.sample(ones, len(zeros))\n",
    "    indices = zeros + ones\n",
    "    X = data[indices]\n",
    "    y = label[indices]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_with_kfold(best_clf, x, y, org_dt, org_lb):\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='accuracy')\n",
    "    print(\"balanced accuracy\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='accuracy')\n",
    "    print(\"unbalanced accuracy\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='precision')\n",
    "    print(\"balanced precision\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='precision')\n",
    "    print(\"unbalanced precision\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='recall')\n",
    "    print(\"balanced recall\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='recall')\n",
    "    print(\"unbalanced recall\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='f1')\n",
    "    print(\"balanced f1\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='f1')\n",
    "    print(\"unbalanced f1\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=10, scoring='roc_auc')\n",
    "    print(\"balanced auc\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=10, scoring='roc_auc')\n",
    "    print(\"unbalanced auc\", np.mean(cros_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data.mat')\n",
    "org_dat = mat['OriginalData']\n",
    "stand_dat = mat['Scaled_Standardization']\n",
    "minmax_dat = mat['Scaled_Min_Max']\n",
    "label = mat['label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM With Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'kernel': ['linear', 'poly', 'rbf'], 'random_state': [i], 'C': [1, 2, 3, 4, 5]}\n",
    "\n",
    "    clf = GridSearchCV(SVC(probability=True), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of SVM Results Using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('svc', svc)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "lime_local = lime.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('svc', svc)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "lime_local = lime.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM With Not Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_sc = 0\n",
    "# best_x = []\n",
    "# best_y = []\n",
    "# best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     random.seed(i)\n",
    "#     X, y = balance_dt(org_dat, label, seed=i)\n",
    "\n",
    "#     parameters = {'kernel': ['linear', 'poly', 'rbf'], 'random_state': [i], 'C': [1, 2, 3, 4, 5]}\n",
    "\n",
    "#     clf = GridSearchCV(SVC(probability=True), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "#     clf.fit(X, y)\n",
    "\n",
    "#     if clf.best_score_ > best_sc:\n",
    "#         best_sc = clf.best_score_\n",
    "#         best_es = clf.best_estimator_\n",
    "#         best_x = X\n",
    "#         best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"-----------------Results--------------------\")\n",
    "# print(\"Best score: \", best_sc)\n",
    "# print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of SVM Results Using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(org_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('svc', svc)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "lime_local = lime.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "seed = 1\n",
    "X = org_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('svc', svc)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "lime_local = lime.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN With Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'activation': ['relu'], 'solver': ['sgd'],\n",
    "                  'learning_rate': ['constant'],\n",
    "                  'hidden_layer_sizes': (90,),\n",
    "                  'max_iter': [200, 500, 1000], 'random_state': [i]}\n",
    "\n",
    "    clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of CNN Results Using Kernel SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "cnn = MLPClassifier(random_state = seed, max_iter=200)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('cnn', cnn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "shap = ShapKernel(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "shap_local = shap.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "cnn = MLPClassifier(random_state = seed, max_iter=200)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('cnn', cnn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "shap = ShapKernel(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "shap_local = shap.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN With Not Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n",
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(org_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'activation': ['relu'], 'solver': ['sgd'],\n",
    "                  'learning_rate': ['constant'],\n",
    "                  'hidden_layer_sizes': (90,),\n",
    "                  'max_iter': [200, 500, 1000], 'random_state': [i]}\n",
    "\n",
    "    clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.6696088108227871\n",
      "MLPClassifier(hidden_layer_sizes=90, random_state=0, solver='sgd')\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.5073737035797926\n",
      "unbalanced accuracy 0.7554485797251453\n",
      "balanced precision 0.5037416068822991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unbalanced precision 0.021311475409836064\n",
      "balanced recall 0.9983606557377049\n",
      "unbalanced recall 0.021311475409836064\n",
      "balanced f1 0.6696088108227871\n",
      "unbalanced f1 0.021311475409836064\n",
      "balanced auc 0.5049314700349369\n",
      "unbalanced auc 0.798888091664751\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of CNN Results Using Kernel SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "seed = 1\n",
    "X, y = balance_dt(org_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "cnn = MLPClassifier(random_state = seed, max_iter=200)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('cnn', cnn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "shap = ShapKernel(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "shap_local = shap.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "seed = 1\n",
    "X = org_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "cnn = MLPClassifier(random_state = seed, max_iter=200)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('cnn', cnn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "shap = ShapKernel(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "shap_local = shap.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree With Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None\n",
    "initial_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'criterion': ['gini', 'entropy'],\n",
    "                  'min_samples_leaf': np.arange(1, 10),\n",
    "                  'min_samples_split': np.arange(2, 10), 'random_state': [i], }\n",
    "\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Decision Tree Using Glassbox Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "dt = ClassificationTree(random_state=seed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_global = dt.explain_global()\n",
    "\n",
    "show(dt_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "dt = ClassificationTree(random_state=seed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_global = dt.explain_global()\n",
    "\n",
    "show(dt_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree With Not Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None\n",
    "initial_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(org_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'criterion': ['gini', 'entropy'],\n",
    "                  'min_samples_leaf': np.arange(1, 10),\n",
    "                  'min_samples_split': np.arange(2, 10), 'random_state': [i], }\n",
    "\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.6257608649687237\n",
      "DecisionTreeClassifier(min_samples_leaf=9, random_state=4)\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.6506490465038474\n",
      "unbalanced accuracy 0.7198457535506871\n",
      "balanced precision 0.6481940997052794\n",
      "unbalanced precision 0.4931306683568743\n",
      "balanced recall 0.6140677062508331\n",
      "unbalanced recall 0.3646208183393309\n",
      "balanced f1 0.6257608649687237\n",
      "unbalanced f1 0.3536949511516238\n",
      "balanced auc 0.6871947395905027\n",
      "unbalanced auc 0.6460849106808653\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Decision Tree Using Glassbox Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(org_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "dt = ClassificationTree(random_state=seed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_global = dt.explain_global()\n",
    "\n",
    "show(dt_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "seed = 1\n",
    "X = org_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "dt = ClassificationTree(random_state=seed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_global = dt.explain_global()\n",
    "\n",
    "show(dt_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression With Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "                  'random_state': [i], 'max_iter': [100, 300, 500, 1000]}\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='recall')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Logistic Regression Using Glassbox Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import LogisticRegression\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "lr = LogisticRegression(random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import LogisticRegression\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "lr = LogisticRegression(random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression With Not Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(org_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "                  'random_state': [i], 'max_iter': [100, 300, 500, 1000]}\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='recall')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.9844262295081968\n",
      "LogisticRegression(random_state=3, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.5102559384409502\n",
      "unbalanced accuracy 0.7514713069978725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced precision 0.5050745643395572\n",
      "unbalanced precision 0.3779363060048535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced recall 0.9844262295081968\n",
      "unbalanced recall 0.10901639344262293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced f1 0.6675463588563378\n",
      "unbalanced f1 0.13581061277717327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced auc 0.7233020999250572\n",
      "unbalanced auc 0.7858432607414777\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Logistic Regression Using Glassbox Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import LogisticRegression\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(org_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "lr = LogisticRegression(random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import LogisticRegression\n",
    "\n",
    "seed = 1\n",
    "X = org_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "lr = LogisticRegression(random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN With Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'n_neighbors': np.arange(1, 11), 'p': [1, 2]}\n",
    "\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='recall')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting KNN Using Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('knn', knn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "pdp = PartialDependence(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "pdp_global = pdp.explain_global()\n",
    "\n",
    "show(pdp_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('knn', knn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "pdp = PartialDependence(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "pdp_global = pdp.explain_global()\n",
    "\n",
    "show(pdp_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN With Not Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(org_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'n_neighbors': np.arange(1, 11), 'p': [1, 2]}\n",
    "\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='recall')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.6723603211776513\n",
      "unbalanced accuracy 0.7467371772756024\n",
      "balanced precision 0.6605113150119803\n",
      "unbalanced precision 0.6039004449628574\n",
      "balanced recall 0.6484606157536985\n",
      "unbalanced recall 0.30399840063974415\n",
      "balanced f1 0.6467209275755886\n",
      "unbalanced f1 0.3197886957772048\n",
      "balanced auc 0.719744397323038\n",
      "unbalanced auc 0.6906640722859024\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting KNN Using Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "seed = 1\n",
    "X, y = balance_dt(org_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('knn', knn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "pdp = PartialDependence(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "pdp_global = pdp.explain_global()\n",
    "\n",
    "show(pdp_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "seed = 1\n",
    "X = org_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('knn', knn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "pdp = PartialDependence(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "pdp_global = pdp.explain_global()\n",
    "\n",
    "show(pdp_global)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
