{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import scipy.io\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from interpret import show\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dt(data, label, seed=None):\n",
    "    random.seed(seed)\n",
    "    ones = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 1:\n",
    "            ones.append(i)\n",
    "    zeros = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 0:\n",
    "            zeros.append(i)\n",
    "    zeros = random.sample(zeros, len(ones))\n",
    "    indices = zeros + ones\n",
    "    X = data[indices]\n",
    "    y = label[indices]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_reversed(data, label, seed=None):\n",
    "    random.seed(seed)\n",
    "    zeros = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 0:\n",
    "            zeros.append(i)\n",
    "    ones = []\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 1:\n",
    "            ones.append(i)\n",
    "    ones = random.sample(ones, len(zeros))\n",
    "    indices = zeros + ones\n",
    "    X = data[indices]\n",
    "    y = label[indices]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_with_kfold(best_clf, x, y, org_dt, org_lb):\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=5, scoring='accuracy')\n",
    "    print(\"cross_res accuracy\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=5, scoring='accuracy')\n",
    "    print(\"cross_res accuracy\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=5, scoring='precision')\n",
    "    print(\"cross_res precision\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=5, scoring='precision')\n",
    "    print(\"cross_res precision\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=5, scoring='recall')\n",
    "    print(\"cross_res recall\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=5, scoring='recall')\n",
    "    print(\"cross_res recall\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=5, scoring='f1')\n",
    "    print(\"cross_res f1\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=5, scoring='f1')\n",
    "    print(\"cross_res f1\", np.mean(cros_res))\n",
    "\n",
    "    cros_res = cross_val_score(best_clf, x, y, cv=5, scoring='roc_auc')\n",
    "    print(\"cross_res auc\", np.mean(cros_res))\n",
    "    cros_res = cross_val_score(best_clf, org_dt, org_lb, cv=5, scoring='roc_auc')\n",
    "    print(\"cross_res auc\", np.mean(cros_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('data.mat')\n",
    "org_dat = mat['OriginalData']\n",
    "stand_dat = mat['Scaled_Standardization']\n",
    "minmax_dat = mat['Scaled_Min_Max']\n",
    "label = mat['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'kernel': ['linear', 'poly', 'rbf'], 'random_state': [i], 'C': [1, 2, 3, 4, 5]}\n",
    "\n",
    "    clf = GridSearchCV(SVC(probability=True), parameters, n_jobs=-1, cv=5, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.6049742303182392\n",
      "SVC(C=5, probability=True, random_state=2)\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res accuracy 0.68297797445439\n",
      "cross_res accuracy 0.7522291038345541\n",
      "cross_res precision 0.7297626104702991\n",
      "cross_res precision 0.755096695419276\n",
      "cross_res recall 0.5321846771495483\n",
      "cross_res recall 0.20327199732351958\n",
      "cross_res f1 0.6049742303182392\n",
      "cross_res f1 0.19436882770031502\n",
      "cross_res auc 0.7546604489686226\n",
      "cross_res auc 0.6229464250418264\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of SVM Results Using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/interpret/visual/udash.py:5: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/interpret/visual/udash.py:6: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/interpret/visual/udash.py:7: UserWarning: \n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n",
      "  import dash_table as dt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140419216027168/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140419216027168/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('svc', svc)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "lime_local = lime.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140419213769360/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140419213769360/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "svc = SVC(gamma='auto', probability=True)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('svc', svc)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "lime = LimeTabular(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "lime_local = lime.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'activation': ['relu'], 'solver': ['sgd'],\n",
    "                  'learning_rate': ['constant'],\n",
    "                  'hidden_layer_sizes': (90,),\n",
    "                  'max_iter': [200, 500, 1000], 'random_state': [i]}\n",
    "\n",
    "    clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv=5, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.317554167263463\n",
      "MLPClassifier(hidden_layer_sizes=90, random_state=4, solver='sgd')\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res accuracy 0.5139210164604915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res accuracy 0.7647289243142324\n",
      "cross_res precision 0.5256572600178505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res precision 0.0851063829787234\n",
      "cross_res recall 0.28401472064235533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res recall 0.04918032786885246\n",
      "cross_res f1 0.317554167263463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res f1 0.06233766233766234\n",
      "cross_res auc 0.6261832730942418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res auc 0.7862203900874346\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of CNN Results Using Kernel SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nayanayeshlur/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning:\n",
      "\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "\n",
      "Using 1953 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d024b7532aa4cb6877233c7b42b2d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140419179542704/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140419179542704/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "cnn = MLPClassifier(random_state = seed, max_iter=200)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('cnn', cnn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "shap = ShapKernel(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "shap_local = shap.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Using 4223 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7426db4033c42678176c7031e359997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140419214046928/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140419214046928/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "cnn = MLPClassifier(random_state = seed, max_iter=200)\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('cnn', cnn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "shap = ShapKernel(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "shap_local = shap.explain_local(X_test[:5], y_test[:5])\n",
    "\n",
    "show(shap_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None\n",
    "initial_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'criterion': ['gini', 'entropy'],\n",
    "                  'min_samples_leaf': np.arange(1, 10),\n",
    "                  'min_samples_split': np.arange(2, 10), 'random_state': [i], }\n",
    "\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(), parameters, n_jobs=-1, cv=5, verbose=1, scoring='f1')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.6036012839251541\n",
      "DecisionTreeClassifier(min_samples_leaf=8, random_state=4)\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res accuracy 0.6309832713131517\n",
      "cross_res accuracy 0.716058272296424\n",
      "cross_res precision 0.6344414038179046\n",
      "cross_res precision 0.47967292161124675\n",
      "cross_res recall 0.5838039478086315\n",
      "cross_res recall 0.35390097022415523\n",
      "cross_res f1 0.6036012839251541\n",
      "cross_res f1 0.34295680184839744\n",
      "cross_res auc 0.6549851161910611\n",
      "cross_res auc 0.630143910859796\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Decision Tree Using Glassbox Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140418242535328/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140418242535328/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "dt = ClassificationTree(random_state=seed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_global = dt.explain_global()\n",
    "\n",
    "show(dt_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140419242176912/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140419242176912/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ClassificationTree\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "dt = ClassificationTree(random_state=seed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "dt_global = dt.explain_global()\n",
    "\n",
    "show(dt_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'solver': ['liblinear', 'lbfgs', 'newton-cg', 'sag', 'saga'],\n",
    "                  'random_state': [i], 'max_iter': [100, 300, 500, 1000]}\n",
    "\n",
    "    clf = GridSearchCV(LogisticRegression(), parameters, n_jobs=-1, cv=10, verbose=1, scoring='recall')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.3575303212048514\n",
      "LogisticRegression(random_state=1, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res accuracy 0.6280775419893392\n",
      "cross_res accuracy 0.7563955909808989\n",
      "cross_res precision 0.7118961041350811\n",
      "cross_res precision 0.583573132261291\n",
      "cross_res recall 0.35449648711943793\n",
      "cross_res recall 0.14097022415523586\n",
      "cross_res f1 0.4546781872551066\n",
      "cross_res f1 0.15466288663067346\n",
      "cross_res auc 0.7405252592840414\n",
      "cross_res auc 0.7823556580130802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Logistic Regression Using Glassbox Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140418242987536/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140418242987536/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import LogisticRegression\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "lr = LogisticRegression(random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140418242818736/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140418242818736/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import LogisticRegression\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "lr = LogisticRegression(random_state = seed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr_global = lr.explain_global()\n",
    "show(lr_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explainable Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140419216003136/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140419216003136/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "ebm = ExplainableBoostingClassifier(random_state=seed)\n",
    "ebm.fit(X_train, y_train)\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140419242178208/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140419242178208/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "ebm = ExplainableBoostingClassifier(random_state=seed)\n",
    "ebm.fit(X_train, y_train)\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sc = 0\n",
    "best_x = []\n",
    "best_y = []\n",
    "best_es = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    random.seed(i)\n",
    "    X, y = balance_dt(minmax_dat, label, seed=i)\n",
    "\n",
    "    parameters = {'n_neighbors': np.arange(1, 11), 'p': [1, 2]}\n",
    "\n",
    "    clf = GridSearchCV(KNeighborsClassifier(), parameters, n_jobs=-1, cv=5, verbose=1, scoring='recall')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if clf.best_score_ > best_sc:\n",
    "        best_sc = clf.best_score_\n",
    "        best_es = clf.best_estimator_\n",
    "        best_x = X\n",
    "        best_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Results--------------------\n",
      "Best score:  0.642746738039478\n",
      "KNeighborsClassifier(n_neighbors=9)\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Results--------------------\")\n",
    "print(\"Best score: \", best_sc)\n",
    "print(best_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_res accuracy 0.6620956116530893\n",
      "cross_res accuracy 0.738216106563263\n",
      "cross_res precision 0.6550884474345563\n",
      "cross_res precision 0.5941450182356907\n",
      "cross_res recall 0.642746738039478\n",
      "cross_res recall 0.31216125794580124\n",
      "cross_res f1 0.641752649972487\n",
      "cross_res f1 0.31568553609894884\n",
      "cross_res auc 0.7118511523125779\n",
      "cross_res auc 0.6835935412889341\n"
     ]
    }
   ],
   "source": [
    "eval_with_kfold(best_es, best_x, best_y, minmax_dat, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting KNN Using Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140419178800848/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140419178800848/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "seed = 1\n",
    "X, y = balance_dt(minmax_dat, label, seed = seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('knn', knn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "pdp = PartialDependence(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "pdp_global = pdp.explain_global()\n",
    "\n",
    "show(pdp_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7043/140418243058272/ -->\n",
       "<iframe src=\"http://127.0.0.1:7043/140418243058272/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "seed = 1\n",
    "X = minmax_dat\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = seed)\n",
    "\n",
    "pca = PCA()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "blackbox_model = Pipeline([('pca', pca), ('knn', knn)])\n",
    "blackbox_model.fit(X_train, y_train)\n",
    "\n",
    "pdp = PartialDependence(predict_fn=blackbox_model.predict_proba, data=X_train)\n",
    "pdp_global = pdp.explain_global()\n",
    "\n",
    "show(pdp_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (base)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
